{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12653317,"sourceType":"datasetVersion","datasetId":7996459}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom glob import glob\n\ndef load_uc_merced_dataset(base_path=\"/kaggle/input/image-retrivel/UCMerced_LandUse\"):\n    data = []\n    labels = []\n    classes = sorted(os.listdir(base_path))\n    \n    for label in classes:\n        img_paths = glob(os.path.join(base_path, label, '*.tif'))\n        for path in img_paths:\n            img = cv2.imread(path)\n            img = cv2.resize(img, (256, 256))\n            data.append(img)\n            labels.append(label)\n    \n    return np.array(data), np.array(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T17:52:21.432632Z","iopub.execute_input":"2025-08-02T17:52:21.432856Z","iopub.status.idle":"2025-08-02T17:52:21.665716Z","shell.execute_reply.started":"2025-08-02T17:52:21.432833Z","shell.execute_reply":"2025-08-02T17:52:21.664876Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def extract_color_histogram(image):\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    hist = cv2.calcHist([hsv], [0, 1, 2], None, [8, 8, 8],\n                        [0, 180, 0, 256, 0, 256])\n    return cv2.normalize(hist, hist).flatten()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T17:55:41.822664Z","iopub.execute_input":"2025-08-02T17:55:41.823196Z","iopub.status.idle":"2025-08-02T17:55:41.827751Z","shell.execute_reply.started":"2025-08-02T17:55:41.823169Z","shell.execute_reply":"2025-08-02T17:55:41.827070Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# ðŸŒ¾ Texture Features (GLCM)\ndef extract_texture_glcm(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    glcm = graycomatrix(gray, [1], [0, np.pi/4, np.pi/2], 256, symmetric=True, normed=True)\n    features = [graycoprops(glcm, prop).flatten() for prop in \n                ['contrast', 'correlation', 'energy', 'homogeneity']]\n    return np.concatenate(features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T17:55:51.847859Z","iopub.execute_input":"2025-08-02T17:55:51.848464Z","iopub.status.idle":"2025-08-02T17:55:51.852855Z","shell.execute_reply.started":"2025-08-02T17:55:51.848438Z","shell.execute_reply":"2025-08-02T17:55:51.852213Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Shape Features (Hu Moments)\ndef extract_shape_features(image):\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    if contours:\n        largest = max(contours, key=cv2.contourArea)\n        moments = cv2.HuMoments(cv2.moments(largest)).flatten()\n        # Log scale transform with sign\n        return -np.sign(moments) * np.log10(np.abs(moments) + 1e-10)\n    else:\n        return np.zeros(7)\n\n# Combine all features into one hybrid vector\ndef build_feature_vector(image):\n    color = extract_color_histogram(image)\n    texture = extract_texture_glcm(image)\n    shape = extract_shape_features(image)\n    return np.concatenate([color, texture, shape])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T17:56:04.837443Z","iopub.execute_input":"2025-08-02T17:56:04.837715Z","iopub.status.idle":"2025-08-02T17:56:04.843467Z","shell.execute_reply.started":"2025-08-02T17:56:04.837694Z","shell.execute_reply":"2025-08-02T17:56:04.842744Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Step 3: Main Execution\nif __name__ == \"__main__\":\n    print(\"ðŸ”„ Loading dataset...\")\n    images, labels = load_uc_merced_dataset(\"/kaggle/input/image-retrivel/UCMerced_LandUse/Images\")\n\n    print(\"ðŸ§  Extracting hybrid features...\")\n    feature_vectors = []\n    for img in images:\n        feat = build_feature_vector(img)\n        feature_vectors.append(feat)\n\n    features = np.array(feature_vectors)\n    print(f\"âœ… Done. Feature matrix shape: {features.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T17:57:11.173671Z","iopub.execute_input":"2025-08-02T17:57:11.173948Z","iopub.status.idle":"2025-08-02T17:58:27.435855Z","shell.execute_reply.started":"2025-08-02T17:57:11.173929Z","shell.execute_reply":"2025-08-02T17:58:27.434987Z"}},"outputs":[{"name":"stdout","text":"ðŸ”„ Loading dataset...\nðŸ§  Extracting hybrid features...\nâœ… Done. Feature matrix shape: (2100, 531)\n","output_type":"stream"}],"execution_count":12}]}